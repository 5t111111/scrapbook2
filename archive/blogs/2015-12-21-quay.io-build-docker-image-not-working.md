# Docker Build, or not to Docker Build

...or: Don't be lazy, build your images on your own computer !

[Quay.io](https://quay.io/) is Docker image repo (similar like [Docker Hub](https://hub.docker.com/))
where you can store your docker images or configure automatic built of
docker images when you push to certain Github branches. For example in my current role
there was a configured Github push trigger on branch `heads/live-*` (e.g. `live-20151221_0001`) to automatically build the image. After build is done I'll just use this image
to deploy to my server (Heroku, AWS ElasticBeanstalk, DigitalOcean,...).

First of all don't get me wrong, I really enjoyed Quay.io and ideas behind
it + I'm a huge fan of any automation that could be done outside of my
laptop (as I've use to write WebServer backend code on a Chromebook before :) ).
It just I found Quay automatic built problematic for the project I'm working
currently.

Now the Quay.io automatic build works like a charm for most application.
My platform is Ruby on Rails monolith app
with butload of JS asset copilation to CDN and
therefore `Dockerfile` is bit tricky.

So long story short: When I built the docker image on my laptop

`docker build -t=quay.io/myorg/myproject:live-20151221_0001 .`

...and pushed to Quay.io

`docker push quay.io/myorg/myproject:live-20151221_0001`

... my AWS Elastic Beanstalk deployent with this tag worked like a charm.

But when I let the Quay.io to build the docker image for me from Github
branch, it seems that one part went wrong. I cannot go to much
details into this, but the point of this article is the idea/question **who
should be building the Docker image in first place**.

Letting service like Quay.io or custom build machine make perfect sence.
The setup is same for everyone, Junior developers don't have to care
about advanced Docker topics, when you have slow internet conection from
where you work it's a life saver,...

But if you are not building your production Docker images on your laptop
how do you know if they work before you push them live?
Of course that's why we have different environment
servers like Staging, or QA where we push the image before release, or
we can just build them remotly and just pull them to our laptops, but
that's not really my point.

I'm still new to Docker (well I think we all are as it's relatively new
technology) but when I started learning late 2014 every other talk I
watched presented Docker as a way how to "ship the same container that
you have in your laptop to production and it just work".

For me Docker is more than just tool for `production`. For me is also a
`development` tool (write application code for Docker running container
via linked folder ) and `test` env tool (run tests on a container)
so it makes perfect sence for me to build the
production Docker image on my laptop as well and then ship it when/if it works.

That being said I don't stand any groud here. It may just happen that I'll
update this article in few months with few more lines in favor of remote
build idea.

All I'm saying is there is no rigt or wrong. There is no harm in trying
new tools and new approaches to tools, Just always reevaluate
after certain time if you and your
team are more or less productive. For now I'm favor of building my
docker images in my laptop and hiding my Chromebook to wardrobe :).

relative keywords:

* Image built by Quay.io doesn't work
